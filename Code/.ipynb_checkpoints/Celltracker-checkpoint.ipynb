{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Tracking Program\n",
    "<br><MTMarkdownOptions output='html4'>\n",
    "    The propose of this project is to develop an algorithm to realize HeLa cell cycle analysis by cell segmentation and cell tracking. Our segmentation algorithm includes binarization, nuclei center detection and nuclei boundary delineating; and our tracking algorithm includes neighboring graph construction, optimal matching, cell division, death, segmentation errors detection and processing, and refined segmentation and matching results. Our chosen testing and training datasets are Histone 2B (H2B)-GFP expressing HeLa cells provided by Mitocheck Consortium. This project used Jaccard index to measure the segmentation accuracy and TRA method for tracking. Our results, respectably 69.51% and 74.61%, demonstrated the validity of the developed algorithm in investigation of cancer cell cycle, the problems and further improvements of our algorithm are also mentioned. \n",
    "</MTMarkdownOptions><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prepare Import File and Import Image Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import sys\n",
    "import numpy as np\n",
    "from IPython.display import Image, display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "def normalize(image):\n",
    "    '''\n",
    "    This function is to normalize the input grayscale image by\n",
    "    substracting globle mean and dividing standard diviation for\n",
    "    visualization. \n",
    "\n",
    "    Input:  a grayscale image\n",
    "\n",
    "    Output: normolized grascale image\n",
    "\n",
    "    '''\n",
    "    cv2.normalize(image, image, 0, 255, cv2.NORM_MINMAX)\n",
    "    return image\n",
    "\n",
    "# read image sequence\n",
    "path = \"PATH_TO_IMAGES\" # The dataset could be download through: http://www.codesolorzano.com/Challenges/CTC/Datasets.html\n",
    "for r,d,f in os.walk(path):\n",
    "    images = []\n",
    "    enhance_images = []\n",
    "    f = sorted(f)\n",
    "    for files in f:\n",
    "        if files[-3:].lower()=='tif':\n",
    "            temp = cv2.imread(os.path.join(r,files))\n",
    "            gray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY) \n",
    "            images.append(gray.copy())\n",
    "            enhance_images.append(normalize(gray.copy()))\n",
    "\n",
    "print \"Total number of image is \", len(images)\n",
    "print \"The shape of image is \", images[0].shape, type(images[0][0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def display_image(img):\n",
    "    assert img.ndim == 2 or img.ndim == 3\n",
    "    h, w = img.shape[:2]\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.resize(img, (w/3, h/3, 3))\n",
    "    else:\n",
    "        img = cv2.resize(img, (w/3, h/3))\n",
    "    cv2.imwrite(\"temp_img.png\", img)\n",
    "    img = Image(\"temp_img.png\")\n",
    "    display(img)\n",
    "\n",
    "def vis_square(data, title=None):\n",
    "    \"\"\"\n",
    "    Take an array of shape (n, height, width) or (n, height, width, 3)\n",
    "    and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\n",
    "    \"\"\"\n",
    "    # resize image into small size\n",
    "    _, h, w = data.shape[:3] \n",
    "    width = int(np.ceil(1200. / np.sqrt(data.shape[0])))    # the width of showing image \n",
    "    height = int(np.ceil(h*float(width)/float(w))) # the height of showing image \n",
    "    if len(data.shape) == 4:\n",
    "        temp = np.zeros((data.shape[0], height, width, 3))\n",
    "    else:\n",
    "        temp = np.zeros((data.shape[0], height, width))\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        if len(data.shape) == 4:\n",
    "            temp[i] = cv2.resize(data[i], (width, height, 3))\n",
    "        else:\n",
    "            temp[i] = cv2.resize(data[i], (width, height))\n",
    "    \n",
    "    data = temp\n",
    "    \n",
    "    # force the number of filters to be square\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = (((0, n ** 2 - data.shape[0]),\n",
    "              (0, 2), (0, 2))                 # add some space between filters\n",
    "              + ((0, 0),) * (data.ndim - 3))  # don't pad the last dimension (if there is one)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=255)  # pad with ones (white)\n",
    "    \n",
    "    # tile the filters into an image\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    \n",
    "    # show image\n",
    "    cv2.imwrite(\"temp_img.png\", data)\n",
    "    img = Image(\"temp_img.png\")\n",
    "    display(img)\n",
    "\n",
    "def cvt_npimg(images):\n",
    "    \"\"\"\n",
    "    Convert image sequence to numpy array\n",
    "    \"\"\"\n",
    "    h, w = images[0].shape[:2]\n",
    "    if len(images[0].shape) == 3:\n",
    "        out = np.zeros((len(images), h, w, 3))\n",
    "    else:\n",
    "        out = np.zeros((len(images), h, w))\n",
    "    for i, img in enumerate(images):\n",
    "        out[i] = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write image from different input\n",
    "def write_mask16(images, name, index=-1):\n",
    "    \"\"\"\n",
    "    Write image as 16 bits image\n",
    "    \"\"\"\n",
    "    if index == -1:\n",
    "        for i, img in enumerate(images):\n",
    "            if i < 10:\n",
    "                cv2.imwrite(name+\"00\"+str(i)+\".tif\", img.astype(np.uint16))\n",
    "            elif i >= 10 and i < 100:\n",
    "                cv2.imwrite(name+\"0\"+str(i)+\".tif\", img.astype(np.uint16))\n",
    "            else:\n",
    "                cv2.imwrite(name+str(i)+\".tif\", img.astype(np.uint16))\n",
    "    else:\n",
    "        if index < 10:\n",
    "            cv2.imwrite(name+\"00\"+str(index)+\".tif\", images.astype(np.uint16))\n",
    "        elif index >= 10 and index < 100:\n",
    "            cv2.imwrite(name+\"0\"+str(index)+\".tif\", images.astype(np.uint16))\n",
    "        else:\n",
    "            cv2.imwrite(name+str(index)+\".tif\", images.astype(np.uint16))   \n",
    "\n",
    "def write_mask8(images, name, index=-1):\n",
    "    \"\"\"\n",
    "    Write image as 8 bits image\n",
    "    \"\"\"\n",
    "    if index == -1:\n",
    "        for i, img in enumerate(images):\n",
    "            if i < 10:\n",
    "                cv2.imwrite(name+\"00\"+str(i)+\".tif\", img.astype(np.uint8))\n",
    "            elif i >= 10 and i < 100:\n",
    "                cv2.imwrite(name+\"0\"+str(i)+\".tif\", img.astype(np.uint8))\n",
    "            else:\n",
    "                cv2.imwrite(name+str(i)+\".tif\", img.astype(np.uint8))\n",
    "    else:\n",
    "        if index < 10:\n",
    "            cv2.imwrite(name+\"000\"+str(index)+\".tif\", images.astype(np.uint8))\n",
    "        elif index >= 10 and index < 100:\n",
    "            cv2.imwrite(name+\"00\"+str(index)+\".tif\", images.astype(np.uint8))\n",
    "        elif index >= 100 and index < 1000:\n",
    "            cv2.imwrite(name+\"0\"+str(index)+\".tif\", images.astype(np.uint8)) \n",
    "        elif index >= 1000 and index < 10000:\n",
    "            cv2.imwrite(name+str(index)+\".tif\", images.astype(np.uint8)) \n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def write_pair8(images, name, index=-1):\n",
    "    \"\"\"\n",
    "    Write image as 8 bits image with dilation\n",
    "    \"\"\"\n",
    "    for i, img in enumerate(images):    \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "        img = cv2.dilate((img*255).astype(np.uint8),kernel,iterations = 3)\n",
    "        if i < 10:\n",
    "            cv2.imwrite(name+\"00\"+str(i)+\".tif\", img)\n",
    "        elif i >= 10 and i < 100:\n",
    "            cv2.imwrite(name+\"0\"+str(i)+\".tif\", img)\n",
    "        else:\n",
    "            cv2.imwrite(name+str(i)+\".tif\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cell Segmentatioin Part\n",
    "<br>\n",
    "<MTMarkdownOptions output='html4'>\n",
    "    1. Adaptive Thresholding\n",
    "    <br>\n",
    "    This file is to compute adaptive thresholding of image sequence in \n",
    "    order to generate binary image for Nuclei segmentation.\n",
    "\n",
    "    Problem:\n",
    "    Due to the low contrast of original image, the adaptive thresholding is not working. \n",
    "    Therefore, we change to regular threshold with threshold value as 129.\n",
    "</MTMarkdownOptions>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "th = None\n",
    "img = None\n",
    "\n",
    "class ADPTIVETHRESH():\n",
    "    '''\n",
    "    This class is to provide all function for adaptive thresholding.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, images):\n",
    "        self.images = []\n",
    "        for img in images:\n",
    "            if len(img.shape) == 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            self.images.append(img.copy())\n",
    "\n",
    "    def applythresh(self, threshold = 50):\n",
    "        '''\n",
    "        applythresh function is to convert original image to binary image by thresholding.\n",
    "\n",
    "        Input: image sequence. E.g. [image0, image1, ...]\n",
    "\n",
    "        Output: image sequence after thresholding. E.g. [image0, image1, ...]\n",
    "        '''\n",
    "        out = []\n",
    "        markers = []\n",
    "        binarymark = []\n",
    "\n",
    "        for img in self.images:\n",
    "            img = cv2.GaussianBlur(img,(5,5),0).astype(np.uint8)\n",
    "            _, thresh = cv2.threshold(img,threshold,1,cv2.THRESH_BINARY)\n",
    "\n",
    "            # Using morphlogical operations to imporve the quality of result\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(9,9))\n",
    "            thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            out.append(thresh)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This part is for testing adaptivethresh.py with single image.\n",
    "# Input: an original image\n",
    "# Output: Thresholding image\n",
    "\n",
    "global th\n",
    "global img\n",
    "\n",
    "adaptive = ADPTIVETHRESH(enhance_images)\n",
    "th = adaptive.applythresh(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display images\n",
    "for i,img in enumerate(th):\n",
    "    th[i] = img*255\n",
    "os.chdir(\".\")\n",
    "write_mask8(th, \"thresh\")\n",
    "out = cvt_npimg(th)\n",
    "vis_square(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<MTMarkdownOptions output='html4'>\n",
    "    2. Gradient Filed Vector*\n",
    "    <br>\n",
    "    This file is to compute gradient vector field (GVF) and then find the Nuclei center \n",
    "    with the GVF result. (This part is optinal and I recommend using the distance map directly)\n",
    "</MTMarkdownOptions>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import spatial as sp\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "\n",
    "looplimit = 500\n",
    "\n",
    "newimg = None\n",
    "pair = None\n",
    "\n",
    "def inbounds(shape, indices):\n",
    "    assert len(shape) == len(indices)\n",
    "    for i, ind in enumerate(indices):\n",
    "        if ind < 0 or ind >= shape[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class GVF():\n",
    "    '''\n",
    "    This class contains all function for calculating GVF and its following steps.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, images, thresh):\n",
    "        \n",
    "        self.images = images\n",
    "        self.thresh = thresh\n",
    "\n",
    "    def distancemap(self):\n",
    "        '''\n",
    "        This function is to generate distance map of the thresh image. We use the opencv\n",
    "        function distanceTransform to generate it. Moreover, in this case, we use Euclidiean\n",
    "        Distance (DIST_L2) as a metric of distance. \n",
    "\n",
    "        Input: None\n",
    "\n",
    "        Output: Image distance map\n",
    "\n",
    "        '''\n",
    "        return [cv2.distanceTransform(self.thresh[i], distanceType=2, maskSize=0)\\\n",
    "                for i in range(len(self.thresh))]\n",
    "\n",
    "    def new_image(self, alpha, dismap):\n",
    "        '''\n",
    "        This function is to generate a new image combining the oringal image I0 with\n",
    "        the distance map image Idis by following expression:\n",
    "                                Inew = I0 + alpha*Idis\n",
    "        In this program, we choose alpha as 0.4.\n",
    "\n",
    "        Input: the weight of distance map: alpha\n",
    "               the distance map image\n",
    "\n",
    "        Output: new grayscale image\n",
    "\n",
    "        '''\n",
    "\n",
    "        return [self.images[i] + alpha * dismap[i] for i in range(len(self.thresh))]\n",
    "\n",
    "    def compute_gvf(self, newimage):\n",
    "        '''\n",
    "        This function is to compute the gradient vector of the imput image.\n",
    "\n",
    "        Input: a grayscale image with size, say m * n * # of images\n",
    "\n",
    "        Output: a 3 dimentional image with size, m * n * 2, where the last dimention is\n",
    "        the gradient vector (gx, gy)\n",
    "\n",
    "        '''\n",
    "        kernel_size = 5 # kernel size for blur image before compute gradient\n",
    "        newimage = [cv2.GaussianBlur((np.clip(newimage[i], 0, 255)).astype(np.uint8),(kernel_size,kernel_size),0)\\\n",
    "                    for i in range(len(self.thresh))]\n",
    "        # use sobel operator to compute gradient \n",
    "        temp = np.zeros((newimage[0].shape[0], newimage[0].shape[1], 2), np.float32) # store temp gradient image \n",
    "        gradimg = []  # output gradient images (height * weight * # of images)\n",
    "\n",
    "        for i in range(len(newimage)):\n",
    "            # compute sobel operation in x, y directions\n",
    "            gradx = cv2.Sobel(newimage[i],cv2.CV_64F,1,0,ksize=3)\n",
    "            grady = cv2.Sobel(newimage[i],cv2.CV_64F,0,1,ksize=3)\n",
    "            # add the gradient vector\n",
    "            temp[:,:,0], temp[:,:,1] = gradx, grady\n",
    "            gradimg.append(temp)\n",
    "\n",
    "        return gradimg\n",
    "\n",
    "    def find_certer(self, gvfimage, index):\n",
    "        '''\n",
    "        This function is to find the center of Nuclei.\n",
    "\n",
    "        Input: the gradient vector image (height * weight * 2).\n",
    "\n",
    "        Output: the record image height * weight).\n",
    "\n",
    "        '''\n",
    "        # Initialize a image to record seed candidates.\n",
    "        imgpair = np.zeros(gvfimage.shape[:2])\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "        dilate = cv2.dilate(self.thresh[index].copy(), kernel, iterations = 1)\n",
    "        erthresh = cv2.erode(dilate, kernel, iterations = 3)\n",
    "        while erthresh.sum() > 0:\n",
    "\n",
    "            print \"Image \", index, \"left: \", erthresh.sum(), \"points\"\n",
    "            # Initialize partical coordinates [y, x]\n",
    "            y0, x0 = np.where(erthresh>0)\n",
    "            p0 = np.array([y0[0], x0[0], 1])\n",
    "\n",
    "            # Initialize record coordicates [y, x]\n",
    "            p1 = np.array([5000, 5000, 1])\n",
    "\n",
    "            # mark the first non-zero point of thresh image to 0\n",
    "            erthresh[p0[0], p0[1]] = 0\n",
    "\n",
    "            # a variable to record if the point out of bound of image or \n",
    "            # out of maximum loop times\n",
    "            outbound = False\n",
    "\n",
    "            # count loop times to limit max loop times\n",
    "            count = 0\n",
    "\n",
    "            while sp.distance.cdist([p0],[p1]) > 1:\n",
    "\n",
    "                count += 1\n",
    "                p1 = p0\n",
    "                u = gvfimage[p0[0], p0[1], 1]\n",
    "                v = gvfimage[p0[0], p0[1], 0]\n",
    "                M = np.array([[1, 0, u],\\\n",
    "                              [0, 1, v],\\\n",
    "                              [0, 0, 1]], np.float32)\n",
    "                p0 = M.dot(p0)\n",
    "                if not inbounds(self.thresh[index].shape, (p0[0], p0[1])) or count > looplimit:\n",
    "                    outbound = True\n",
    "                    break\n",
    "\n",
    "            if not outbound:\n",
    "                imgpair[p0[0], p0[1]] += 1\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        return imgpair.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This part is for testing gvf.py with single image. (Optional)\n",
    "# Input: an original image\n",
    "# Output: Thresholding image and seed image\n",
    "\n",
    "global th\n",
    "global newimg\n",
    "global pair\n",
    "# Nuclei center detection\n",
    "gvf = GVF(images, th)\n",
    "dismap = gvf.distancemap()\n",
    "newimg = gvf.new_image(0.4, dismap) # choose alpha as 0.4.\n",
    "gradimg = gvf.compute_gvf(newimg)\n",
    "out = []\n",
    "pair = []\n",
    "pair_raw = []\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "i = 0\n",
    "for i,img in enumerate(gradimg):\n",
    "    imgpair_raw = gvf.find_certer(img, i)\n",
    "    pair_raw.append(imgpair_raw)\n",
    "    neighborhood_size = 20\n",
    "    data_max = ndimage.filters.maximum_filter(pair_raw[i], neighborhood_size)\n",
    "    data_max[data_max==0] = 255\n",
    "    pair.append((pair_raw[i] == data_max).astype(np.uint8))\n",
    "    write_mask8([pair[i]], \"pair_raw\", i)\n",
    "    os.chdir(\"PATH_TO_RESULTS\")\n",
    "    y, x = np.where(pair[i]>0)\n",
    "    points = zip(y[:], x[:])\n",
    "    dmap = distance.cdist(points, points, 'euclidean')\n",
    "    y, x = np.where(dmap<10)\n",
    "    ps = zip(y[:], x[:])\n",
    "    for p in ps:\n",
    "        if p[0] != p[1]:\n",
    "            pair[i][points[min(p[0], p[1])]] = 0\n",
    "    dilation = cv2.dilate((pair[i]*255).astype(np.uint8),kernel,iterations = 3)\n",
    "    out.append(dilation)\n",
    "\n",
    "out = cvt_npimg(out)\n",
    "vis_square(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<MTMarkdownOptions output='html4'>\n",
    "    GVF enhance*\n",
    "    <br>\n",
    "    This file is to amend the seed points for watershed. (This part is optinal and I recommend using the distance map directly)\n",
    "</MTMarkdownOptions>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import spatial as sp\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "\n",
    "gvf = GVF(images, th)\n",
    "dismap = gvf.distancemap()\n",
    "newimg = gvf.new_image(0.4, dismap) # choose alpha as 0.4.\n",
    "# TODO this part is designed to amend the result of gvf. \n",
    "pair = []\n",
    "path=os.path.join(\"PATH_TO_RESULTS\")\n",
    "for r,d,f in os.walk(path):\n",
    "    for files in f:\n",
    "        if files[:5].lower()=='seed':\n",
    "            print files\n",
    "            temp = cv2.imread(os.path.join(r,files))\n",
    "            temp = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY) \n",
    "            y, x = np.where(temp>0)\n",
    "            points = zip(y[:], x[:])\n",
    "            dmap = distance.cdist(points, points, 'euclidean')\n",
    "            y, x = np.where(dmap<10)\n",
    "            ps = zip(y[:], x[:])\n",
    "            for p in ps:\n",
    "                if p[0] != p[1]:\n",
    "                    temp[points[min(p[0], p[1])]] = 0\n",
    "            pair.append(temp)\n",
    "            clear_output(wait=True)\n",
    "print \"finish!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<MTMarkdownOptions output='html4'>\n",
    "    2. Distance Map (Recommend)\n",
    "    <br>\n",
    "    This file uses distance map to generate the seed points for watershed. Although it has nothing to do with GVF, you still need to load the GVF class, since it needs some helper functions in the class.\n",
    "</MTMarkdownOptions>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gvf = GVF(images, th)\n",
    "dismap = gvf.distancemap()\n",
    "newimg = gvf.new_image(0.4, dismap) # choose alpha as 0.4.\n",
    "out = []\n",
    "pair = []\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "for i,img in enumerate(dismap):\n",
    "    neighborhood_size = 20\n",
    "    data_max = ndimage.filters.maximum_filter(img, neighborhood_size)\n",
    "    data_max[data_max==0] = 255\n",
    "    pair.append((img == data_max).astype(np.uint8))\n",
    "    y, x = np.where(pair[i]>0)\n",
    "    points = zip(y[:], x[:])\n",
    "    dmap = distance.cdist(points, points, 'euclidean')\n",
    "    y, x = np.where(dmap<20)\n",
    "    ps = zip(y[:], x[:])\n",
    "    for p in ps:\n",
    "        if p[0] != p[1]:\n",
    "            pair[i][points[min(p[0], p[1])]] = 0\n",
    "    dilation = cv2.dilate((pair[i]*255).astype(np.uint8),kernel,iterations = 1)\n",
    "    out.append(dilation)\n",
    "    os.chdir(\".\")\n",
    "    write_mask8(dilation, \"seed_point\", i)\n",
    "\n",
    "out = cvt_npimg(out)\n",
    "vis_square(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "<MTMarkdownOptions output='html4'>\n",
    "    3. Watershed\n",
    "    <br>\n",
    "    This file is to compute watershed given the seed image in the gvf.py.\n",
    "</MTMarkdownOptions>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import unique\n",
    "import copy as cp\n",
    "\n",
    "bmarks = None\n",
    "marks = None\n",
    "\n",
    "class WATERSHED():\n",
    "    '''\n",
    "    This class contains all the function to compute watershed.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, images, markers):\n",
    "        self.images = images\n",
    "        self.markers = markers\n",
    "\n",
    "    def is_over_long(self, img, max_lenth=50):\n",
    "        rows = np.any(img, axis=1)\n",
    "        cols = np.any(img, axis=0)\n",
    "        if not len(img[img>0]):\n",
    "            return True\n",
    "        rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "        cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "        if (rmax-rmin)>max_lenth or (cmax-cmin)>max_lenth:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def watershed_compute(self):\n",
    "        '''\n",
    "        This function is to compute watershed given the newimage and the seed image\n",
    "        (center candidates). In this function, we use cv2.watershed to implement watershed.\n",
    "\n",
    "        Input: newimage (height * weight * # of images)\n",
    "\n",
    "        Output: watershed images (height * weight * # of images)\n",
    "\n",
    "        '''\n",
    "        result = []\n",
    "        outmark = []\n",
    "        outbinary = []\n",
    "\n",
    "        for i in range(len(self.images)):\n",
    "            print \"image: \", i\n",
    "            # generate a 3-channel image in order to use cv2.watershed\n",
    "            imgcolor = np.zeros((self.images[i].shape[0], self.images[i].shape[1], 3), np.uint8)\n",
    "            for c in range(3): \n",
    "                imgcolor[:,:,c] = self.images[i]\n",
    "\n",
    "            # compute marker image (labelling)\n",
    "            if len(self.markers[i].shape) == 3:\n",
    "                self.markers[i] = cv2.cvtColor(self.markers[i],cv2.COLOR_BGR2GRAY)\n",
    "            _, mark = cv2.connectedComponents(self.markers[i])\n",
    "            \n",
    "            # watershed!\n",
    "            mark = cv2.watershed(imgcolor,mark)\n",
    "            \n",
    "            u, counts = unique(mark, return_counts=True)\n",
    "            counter = dict(zip(u, counts))\n",
    "            for index in counter:\n",
    "                temp_img = np.zeros_like(mark)\n",
    "                temp_img[mark==index] = 255\n",
    "                if self.is_over_long(temp_img):\n",
    "                    mark[mark==index] = 0\n",
    "                    continue\n",
    "                if counter[index] > 3000:\n",
    "                    mark[mark==index] = 0\n",
    "                    continue\n",
    "            \n",
    "            labels = list(set(mark[mark>0]))\n",
    "            length = len(labels)\n",
    "            temp_img = mark.copy()\n",
    "            for original, new in zip(labels, range(1,length+1)):\n",
    "                temp_img[mark==original] = new\n",
    "            mark = temp_img\n",
    "                \n",
    "            # mark image and add to the result \n",
    "            temp = cv2.cvtColor(imgcolor,cv2.COLOR_BGR2GRAY)\n",
    "            result.append(temp)\n",
    "            outmark.append(mark.astype(np.uint8))\n",
    "\n",
    "            binary = mark.copy()\n",
    "            binary[mark>0] = 255\n",
    "            outbinary.append(binary.astype(np.uint8))\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        return result, outbinary, outmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This part is for testing watershed.py with single image.\n",
    "# Output: Binary image after watershed\n",
    "\n",
    "global bmarks\n",
    "global marks\n",
    "\n",
    "# watershed\n",
    "ws = WATERSHED(newimg, pair) \n",
    "wsimage, bmarks, marks = ws.watershed_compute()\n",
    "\n",
    "out = cvt_npimg(np.clip(bmarks, 0, 255)).astype(np.uint8)\n",
    "vis_square(out)\n",
    "os.chdir(\"PATH_TO_RESULT_MASK\")\n",
    "write_mask16(marks, \"mask\")\n",
    "os.chdir(\"PATH_TO_RESULT_BINARY\")\n",
    "write_mask8(out, \"binary\")\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<MTMarkdownOptions output='html4'>\n",
    "    4. Segmentation Evaluation\n",
    "    <br>\n",
    "    This file is to evaluate our algorithm about segmentation in jaccard coefficient.\n",
    "</MTMarkdownOptions>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2pts(ptslist):\n",
    "    list_y = np.array([ptslist[0]])\n",
    "    list_x = np.array([ptslist[1]])\n",
    "    return np.append(list_y, list_x).reshape(2, len(list_y[0])).T\n",
    "\n",
    "def unique_rows(a):\n",
    "    a = np.ascontiguousarray(a)\n",
    "    unique_a = np.unique(a.view([('', a.dtype)]*a.shape[1]))\n",
    "    return unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))\n",
    "\n",
    "# read image sequence\n",
    "# The training set locates at \"resource/training/01\" and \"resource/training/02\"\n",
    "# The ground truth of training set locates at \"resource/training/GT_01\" and \n",
    "# \"resource/training/GT_02\"\n",
    "# The testing set locates at \"resource/testing/01\" and \"resource/testing/02\"\n",
    "\n",
    "path = \"PATH_TO_GT_SEGMENTATION\"\n",
    "gts = []\n",
    "for r,d,f in os.walk(path):\n",
    "    for files in f:\n",
    "        if files[-3:].lower()=='tif':\n",
    "            temp = cv2.imread(os.path.join(r,files), cv2.IMREAD_UNCHANGED)\n",
    "            gts.append([temp, files[-6:-4]])\n",
    "print \"number of gts: \", len(gts)\n",
    "\n",
    "path= \"PATH_TO_SEGMENTATION_RESULTS\"\n",
    "binarymarks = []\n",
    "for r,d,f in os.walk(path):\n",
    "    for files in f:\n",
    "        if files[:4]=='mark':\n",
    "            temp = cv2.imread(os.path.join(r,files))\n",
    "            gray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY) \n",
    "            binarymarks.append([gray, files[-6:-4]])\n",
    "print \"number of segmentation image: \", len(binarymarks)\n",
    "\n",
    "jaccards = []\n",
    "\n",
    "for gt in gts:\n",
    "    for binarymark in binarymarks:\n",
    "        if gt[1] == binarymark[1]:\n",
    "            print \"enter...\", gt[1]\n",
    "            list_pts = set(gt[0][gt[0]>0])\n",
    "            list_seg = set(binarymark[0][binarymark[0]>0])\n",
    "            for pt in list_pts:\n",
    "                for seg in list_seg:\n",
    "                    pts_gt = np.where(gt[0]==pt)\n",
    "                    pts_seg = np.where(binarymark[0]==seg)\n",
    "                    pts_gt = list2pts(pts_gt)\n",
    "\n",
    "                    pts_seg = list2pts(pts_seg)\n",
    "                    pts = np.append(pts_gt, pts_seg).reshape(len(pts_gt)+len(pts_seg),2)\n",
    "                    union_pts = unique_rows(pts)\n",
    "\n",
    "                    union = float(len(union_pts))\n",
    "                    intersection = float(len(pts_seg) + len(pts_gt) - len(union_pts))\n",
    "\n",
    "                    if intersection/union > 0.5:\n",
    "                        jaccards.append(intersection/union)\n",
    "clear_output(wait=True)\n",
    "jaccard = float(sum(jaccards))/float(len(jaccards))\n",
    "print \"jaccard: \", jaccard, \"number of Nuclei: \", len(jaccards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cell Tracking Part\n",
    "<br>\n",
    "<MTMarkdownOptions output='html4'>\n",
    "    1. Graph Construction\n",
    "    <br>\n",
    "    This file is to generate a neighboring graph contraction using \n",
    "    Delaunary Triangulation.\n",
    "</MTMarkdownOptions>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroid = None\n",
    "slope_length = None\n",
    "class GRAPH():\n",
    "    '''\n",
    "    This class contains all the functions needed to compute \n",
    "    Delaunary Triangulation.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, mark, binary, index):\n",
    "        '''\n",
    "        Input: the grayscale mark image with different label on each segments\n",
    "               the binary image of the mark image\n",
    "               the index of the image\n",
    "\n",
    "        '''\n",
    "        self.mark = mark[index]\n",
    "        self.binary = binary[index]\n",
    "              \n",
    "    def rect_contains(self, rect, point):\n",
    "        '''\n",
    "        Check if a point is inside the image\n",
    "\n",
    "        Input: the size of the image \n",
    "               the point that want to test\n",
    "\n",
    "        Output: if the point is inside the image\n",
    "\n",
    "        '''\n",
    "        if point[0] < rect[0] :\n",
    "            return False\n",
    "        elif point[1] < rect[1] :\n",
    "            return False\n",
    "        elif point[0] > rect[2] :\n",
    "            return False\n",
    "        elif point[1] > rect[3] :\n",
    "            return False\n",
    "        return True\n",
    "     \n",
    "    def draw_point(self, img, p, color ):\n",
    "        '''\n",
    "        Draw a point\n",
    "\n",
    "        '''\n",
    "        cv2.circle( img, (p[1], p[0]), 2, color, cv2.FILLED, 16, 0 )\n",
    "     \n",
    "    def draw_delaunay(self, img, subdiv, delaunay_color):\n",
    "        '''\n",
    "        Draw delaunay triangles and store these lines\n",
    "\n",
    "        Input: the image want to draw\n",
    "               the set of points: format as cv2.Subdiv2D\n",
    "               the color want to use\n",
    "\n",
    "        Output: the slope and length of each line ()\n",
    "\n",
    "        '''\n",
    "        triangleList = subdiv.getTriangleList();\n",
    "        size = img.shape\n",
    "        r = (0, 0, size[0], size[1])\n",
    "\n",
    "        slope_length = [[]]\n",
    "        for i in range(self.mark.max()-1):\n",
    "            slope_length.append([])\n",
    "\n",
    "        for t_i, t in enumerate(triangleList):\n",
    "             \n",
    "            pt1 = (int(t[0]), int(t[1]))\n",
    "            pt2 = (int(t[2]), int(t[3]))\n",
    "            pt3 = (int(t[4]), int(t[5]))\n",
    "             \n",
    "            if self.rect_contains(r, pt1) and self.rect_contains(r, pt2) and self.rect_contains(r, pt3):\n",
    "                \n",
    "                # draw lines\n",
    "                cv2.line(img, (pt1[1], pt1[0]), (pt2[1], pt2[0]), delaunay_color, 1, 16, 0)\n",
    "                cv2.line(img, (pt2[1], pt2[0]), (pt3[1], pt3[0]), delaunay_color, 1, 16, 0)\n",
    "                cv2.line(img, (pt3[1], pt3[0]), (pt1[1], pt1[0]), delaunay_color, 1, 16, 0)\n",
    "                \n",
    "                # store the length of line segments and their slopes\n",
    "                for p0 in [pt1, pt2, pt3]:\n",
    "                    for p1 in [pt1, pt2, pt3]:\n",
    "                        if p0 != p1:\n",
    "                            temp = self.length_slope(p0, p1)\n",
    "                            if temp not in slope_length[self.mark[p0]-1]:\n",
    "                                slope_length[self.mark[p0]-1].append(temp)                \n",
    "\n",
    "        return slope_length\n",
    "\n",
    "    def length_slope(self, p0, p1):\n",
    "        '''\n",
    "        This function is to compute the length and theta for the given two points.\n",
    "\n",
    "        Input: two points with the format (y, x)\n",
    "\n",
    "        '''\n",
    "        if p1[1]-p0[1]:\n",
    "            slope = (p1[0]-p0[0]) / (p1[1]-p0[1])\n",
    "        else:\n",
    "            slope = 1e10\n",
    "\n",
    "        length = np.sqrt((p1[0]-p0[0])**2 + (p1[1]-p0[1])**2)\n",
    "\n",
    "        return length, slope\n",
    "\n",
    "    def generate_points(self):\n",
    "        '''\n",
    "        Find the centroid of each segmentation\n",
    "\n",
    "        '''\n",
    "        centroids = []\n",
    "        label = []\n",
    "        max_label = self.mark.max()\n",
    "\n",
    "        for i in range(1, max_label+1):\n",
    "            img = self.mark.copy()\n",
    "            img[img!=i] = 0\n",
    "            if img.sum():\n",
    "                _, contours,hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "                m = cv2.moments(contours[0])\n",
    "\n",
    "                if m['m00']:\n",
    "                    label.append(i)\n",
    "                    centroids.append(( int(round(m['m01']/m['m00'])),\\\n",
    "                                       int(round(m['m10']/m['m00'])) ))\n",
    "                else:\n",
    "                    label.append(i)\n",
    "                    centroids.append(( 0,0 ))\n",
    "\n",
    "        return centroids, label\n",
    "\n",
    "    def run(self, animate = False):\n",
    "        '''\n",
    "        The pipline of graph construction.\n",
    "\n",
    "        Input: if showing a animation (False for default)\n",
    "\n",
    "        Output: centroids: # of segments * 2   (y, x)\n",
    "                slopes and length: # of segments * # of slope_length\n",
    "\n",
    "        '''\n",
    "        # Read in the image.\n",
    "        img_orig = self.binary.copy()\n",
    "         \n",
    "        # Rectangle to be used with Subdiv2D\n",
    "        size = img_orig.shape\n",
    "        rect = (0, 0, size[0], size[1])\n",
    "         \n",
    "        # Create an instance of Subdiv2D\n",
    "        subdiv = cv2.Subdiv2D(rect);\n",
    "        \n",
    "        # find the centroid of each segments\n",
    "        points, label = self.generate_points()\n",
    "\n",
    "\n",
    "        # add and sort the centroid to a numpy array for post processing\n",
    "        centroid = np.zeros((self.mark.max(), 2))\n",
    "        for p, l in zip(points, label):\n",
    "            centroid[l-1] = p\n",
    "\n",
    "        outimg = []\n",
    "        # Insert points into subdiv\n",
    "        for idx_p, p in enumerate(points):\n",
    "            subdiv.insert(p)\n",
    "             \n",
    "            # Show animation\n",
    "            if animate:\n",
    "                img_copy = img_orig.copy()\n",
    "                # Draw delaunay triangles\n",
    "                self.draw_delaunay( img_copy, subdiv, (255, 255, 255));\n",
    "                outimg.append(img_copy)\n",
    "                display_image(img_copy)\n",
    "                img_copy = cv2.resize(img_copy, (314, 200))\n",
    "                cv2.imwrite(\"delaunay_\" + str(idx_p).zfill(3) + \".png\", img_copy)\n",
    "                clear_output(wait=True)\n",
    "                \n",
    "        # Draw delaunay triangles\n",
    "        slope_length = self.draw_delaunay( img_orig, subdiv, (255, 255, 255));\n",
    "     \n",
    "        # Draw points\n",
    "        for p in points :\n",
    "            self.draw_point(img_orig, p, (0,0,255))\n",
    "        \n",
    "        # show images\n",
    "        if animate:\n",
    "            display_image(img_orig)\n",
    "\n",
    "        print \"length of centroid: \", len(centroid)\n",
    "        return centroid, slope_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This part is the small test for graph_contruction.py.\n",
    "# Input:  grayscale marker image\n",
    "#         binary marker image\n",
    "# Output: a text file includes the centroid and the length and slope for each neighbor. \n",
    "\n",
    "# Build Delaunay Triangulation\n",
    "global centroid\n",
    "global slope_length\n",
    "centroid = []\n",
    "slope_length = []\n",
    "for i in range(len(images)):\n",
    "    print \"  graph_construction: image \", i\n",
    "    print \"max pixel: \", marks[i].max()\n",
    "    graph = GRAPH(marks, bmarks, i)\n",
    "    if i == 0:\n",
    "        tempcentroid, tempslope_length = graph.run(True)\n",
    "    else:\n",
    "        tempcentroid, tempslope_length = graph.run()\n",
    "    centroid.append(tempcentroid)\n",
    "    slope_length.append(tempslope_length)\n",
    "    clear_output(wait=True)\n",
    "print \"finish!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<MTMarkdownOptions output='html4'>\n",
    "    2. Matching\n",
    "    <br>\n",
    "    This file is to match nuclei in two consecutive frames by Phase Controlled Optimal Matching. \n",
    "    It includes two part: \n",
    "\t\t1) Dissimilarity measure\n",
    "\t\t2) Matching\n",
    "</MTMarkdownOptions>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from pyefd import elliptic_fourier_descriptors\n",
    "\n",
    "Max_dis = 100000\n",
    "\n",
    "def write_image(image, title, index, imgformat='.tif'):\n",
    "    if index < 10:\n",
    "            name = '00'+str(index)\n",
    "    else:\n",
    "        name = '0'+str(index)\n",
    "    cv2.imwrite(title+name+imgformat, image.astype(np.uint16))\n",
    "\n",
    "class FEAVECTOR():\n",
    "    '''\n",
    "    This class builds a feature vector for each segments.\n",
    "    The format of each vector is: \n",
    "                    v(k,i) = [c(k,i), s(k, i), h(k, i), e(k, i)], where k is the \n",
    "                    index of the image (frame) and i is the label of each segment. \n",
    "\n",
    "                    c(k,i): the centroid of each segment (y, x);\n",
    "                    s(k,i): the binary shape of each segment;\n",
    "                    h(k,i): the intensity distribution (hsitogram) of the segment;\n",
    "                    e(k,i): the spatial distribution of the segment. Its format is \n",
    "                    like (l(k, i, p), theta(k, i, p)), where p represent different\n",
    "                    line connected with different segment. \n",
    "\n",
    "    '''\n",
    "    def __init__(self, centroid=None, shape=None, histogram=None, spatial=None, \\\n",
    "                       ID=None, start = None, end=None, label=None, ratio=None, area=None, cooc=None):\n",
    "        self.c = centroid\n",
    "        self.s = shape\n",
    "        self.h = histogram\n",
    "        self.e = spatial\n",
    "        self.id = ID\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.l = label\n",
    "        self.a = area\n",
    "        self.r = ratio\n",
    "        self.cm = cooc\n",
    "\n",
    "    def add_id(self, num, index):\n",
    "        '''\n",
    "        This function adds cell id for each cell.\n",
    "\n",
    "        '''\n",
    "        if index == 0:\n",
    "            self.id = np.linspace(1, num, num)\n",
    "        else:\n",
    "            self.id= np.linspace(-1, -1, num)\n",
    "\n",
    "    def add_label(self):\n",
    "        '''\n",
    "        This function is to add labels for each neclei for post process.\n",
    "\n",
    "        '''\n",
    "        self.l = np.linspace(0, 0, len(self.c))\n",
    "\n",
    "    def set_centroid(self, centroid):\n",
    "        '''\n",
    "        This function sets the centroid for all neclei.\n",
    "\n",
    "        Input: the set of centroid: # of images * # of neclei * 2 (y, x)\n",
    "\n",
    "        Output: None\n",
    "\n",
    "        '''\n",
    "        self.c = centroid\n",
    "\n",
    "    def set_spatial(self, spatial):\n",
    "        '''\n",
    "        This function sets the spatial distrbution for all neclei.\n",
    "\n",
    "        Input: the set of centroid: # of images * # of neclei * # of line segments (length, slope)\n",
    "\n",
    "        Output: None\n",
    "\n",
    "        '''\n",
    "        self.e = spatial\n",
    "\n",
    "    def set_shape(self, image, marker):\n",
    "        '''\n",
    "        This function sets the binary shape for all necluei.\n",
    "\n",
    "        Input: the original images: # of images * height * weight\n",
    "               the labeled images: # of images * nucei's height * nucei's weight ()\n",
    "\n",
    "        Output: None\n",
    "\n",
    "        '''\n",
    "        def boundingbox(image):\n",
    "            y, x = np.where(image)\n",
    "            return min(x), min(y), max(x), max(y)\n",
    "\n",
    "        shape = []\n",
    "\n",
    "        for label in range(1, marker.max()+1):\n",
    "            tempimg = marker.copy()\n",
    "            tempimg[tempimg!=label] = 0\n",
    "            tempimg[tempimg==label] = 1\n",
    "            if tempimg.sum():\n",
    "                minx, miny, maxx, maxy = boundingbox(tempimg)\n",
    "                shape.append((tempimg[miny:maxy+1, minx:maxx+1], image[miny:maxy+1, minx:maxx+1]))\n",
    "            else:\n",
    "                shape.append(([], []))\n",
    "\n",
    "        self.s = shape\n",
    "\n",
    "    def set_histogram(self):\n",
    "        '''\n",
    "        Note: this function must be implemneted after set_shape().\n",
    "\n",
    "        '''\n",
    "        def computehistogram(image):\n",
    "            h, w = image.shape[:2]\n",
    "            his = np.zeros((256,1))\n",
    "            for y in range(h):\n",
    "                for x in range(w):\n",
    "                    his[image[y, x], 0] += 1\n",
    "            return his\n",
    "\n",
    "        assert self.s != None, \"this function must be implemneted after set_shape().\"\n",
    "\n",
    "        his = []\n",
    "\n",
    "        for j in range(len(self.s)):\n",
    "            img = self.s[j][1]\n",
    "            if len(img):\n",
    "                temphis = computehistogram(img)\n",
    "                his.append(temphis)\n",
    "            else:\n",
    "                his.append(np.zeros((256,1)))\n",
    "\n",
    "        self.h = his\n",
    "\n",
    "    def add_efd(self):\n",
    "        coeffs = []\n",
    "        for i in range(len(self.s)):\n",
    "            try:\n",
    "                _, contours, hierarchy = cv2.findContours(self.s[i][0].astype(np.uint8), 1, 2)\n",
    "                if not len(contours):\n",
    "                    coeffs.append(0)\n",
    "                    continue\n",
    "                cnt = contours[0]\n",
    "                if len(cnt) >= 5:\n",
    "                    contour = []\n",
    "                    for i in range(len(contours[0])):\n",
    "                        contour.append(contours[0][i][0])\n",
    "                    coeffs.append(elliptic_fourier_descriptors(contour, order=10, normalize=False)) \n",
    "                else:\n",
    "                    coeffs.append(0)\n",
    "            except AttributeError:\n",
    "                coeffs.append(0)\n",
    "        self.r = coeffs\n",
    "\n",
    "    def add_co_occurrence(self, level=10):\n",
    "        '''\n",
    "        This funciton is to generate co-occurrence matrix for each cell. The structure of\n",
    "        output coefficients is:\n",
    "        [Entropy, Energy, Contrast, Homogeneity]\n",
    "        '''\n",
    "        # generate P metrix.\n",
    "        self.cm = []\n",
    "        for j in range(len(self.s)):\n",
    "            if not len(self.s[j][1]):\n",
    "                p_0 = np.zeros((level,level))\n",
    "                p_45 = np.zeros((level,level))\n",
    "                p_90 = np.zeros((level,level))\n",
    "                p_135 = np.zeros((level,level))\n",
    "                self.cm.append([np.array([0, 0, 0, 0]),[p_0, p_45, p_90, p_135]])\n",
    "                continue\n",
    "            max_p, min_p = np.max(self.s[j][1]), np.min(self.s[j][1])\n",
    "            range_p = max_p - min_p\n",
    "            img = np.round((np.asarray(self.s[j][1]).astype(np.float32)-min_p)/range_p*level)\n",
    "            h, w = img.shape[:2]\n",
    "            p_0 = np.zeros((level,level))\n",
    "            p_45 = np.zeros((level,level))\n",
    "            p_90 = np.zeros((level,level))\n",
    "            p_135 = np.zeros((level,level))\n",
    "            for y in range(h):\n",
    "                for x in range(w):\n",
    "                    try:\n",
    "                        p_0[img[y,x],img[y,x+1]] += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    try:\n",
    "                        p_0[img[y,x],img[y,x-1]] += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    try:\n",
    "                        p_90[img[y,x],img[y+1,x]] += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    try:\n",
    "                        p_90[img[y,x],img[y-1,x]] += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    try:\n",
    "                        p_45[img[y,x],img[y+1,x+1]] += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    try:\n",
    "                        p_45[img[y,x],img[y-1,x-1]] += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    try:\n",
    "                        p_135[img[y,x],img[y+1,x-1]] += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    try:\n",
    "                        p_135[img[y,x],img[y-1,x+1]] += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "            Entropy, Energy, Contrast, Homogeneity = 0, 0, 0, 0\n",
    "            for y in range(10):\n",
    "                for x in range(10):\n",
    "                    if 0 not in [p_0[y,x], p_45[y,x], p_90[y,x], p_135[y,x]]:\n",
    "                        Entropy -= (p_0[y,x]*np.log2(p_0[y,x])+\\\n",
    "                                    p_45[y,x]*np.log2(p_45[y,x])+\\\n",
    "                                    p_90[y,x]*np.log2(p_90[y,x])+\\\n",
    "                                    p_135[y,x]*np.log2(p_135[y,x]))/4\n",
    "                    else:\n",
    "                        temp = 0\n",
    "                        for p in [p_0[y,x], p_45[y,x], p_90[y,x], p_135[y,x]]:\n",
    "                            if p != 0:\n",
    "                                temp += p*np.log2(p)\n",
    "                        Entropy -= temp/4\n",
    "                    Energy += (p_0[y,x]**2+\\\n",
    "                                p_45[y,x]**2+\\\n",
    "                                p_90[y,x]**2+\\\n",
    "                                p_135[y,x]**2)/4\n",
    "                    Contrast += (x-y)**2*(p_0[y,x]+\\\n",
    "                                        p_45[y,x]+\\\n",
    "                                        p_90[y,x]+\\\n",
    "                                        p_135[y,x])/4\n",
    "                    Homogeneity += (p_0[y,x]+\\\n",
    "                                    p_45[y,x]+\\\n",
    "                                    p_90[y,x]+\\\n",
    "                                    p_135[y,x])/(4*(1+abs(x-y)))\n",
    "            self.cm.append([np.array([Entropy, Energy, Contrast, Homogeneity]),[p_0, p_45, p_90, p_135]])\n",
    "\n",
    "    def add_area(self):\n",
    "        area = []\n",
    "        for i in range(len(self.s)):\n",
    "            area.append(np.count_nonzero(self.s[i][0]))\n",
    "        self.a = area\n",
    "\n",
    "    def generate_vector(self):\n",
    "        '''\n",
    "        This function is to convert the vector maxtrics into a list.\n",
    "\n",
    "        Output: a list of vector: [v0, v1, ....]\n",
    "\n",
    "        '''\n",
    "        vector = []\n",
    "        for i in range(len(self.c)):\n",
    "                vector.append(FEAVECTOR(centroid=self.c[i],shape=self.s[i],\\\n",
    "                                        histogram=self.h[i],spatial=self.e[i],\\\n",
    "                                        ID=self.id[i],label=self.l[i],\\\n",
    "                                        ratio=self.r[i],area=self.a[i], cooc=self.cm[i]))\n",
    "        return vector\n",
    "\n",
    "\n",
    "\n",
    "def set_date(vectors):\n",
    "    '''\n",
    "    This function is to add the start and end frame of each vector and\n",
    "    combine the vector with same id.\n",
    "\n",
    "    Input: the list of vectors in different frames. \n",
    "\n",
    "    Output: the list of vectors of all cell with different id. \n",
    "\n",
    "    '''\n",
    "    max_id = 0\n",
    "    for vector in vectors:\n",
    "        for pv in vector:\n",
    "            if pv.id > max_id:\n",
    "                max_id = pv.id\n",
    "\n",
    "    output = np.zeros((max_id, 4))\n",
    "    output[:,0] = np.linspace(1, max_id, max_id) # set the cell ID\n",
    "    output[:,1] = len(vectors)\n",
    "    for frame, vector in enumerate(vectors):\n",
    "        for pv in vector:\n",
    "            if output[pv.id-1][1] > frame:     # set the start frame\n",
    "                output[pv.id-1][1] = frame\n",
    "            if output[pv.id-1][2] < frame:     # set the end frame\n",
    "                output[pv.id-1][2] = frame\n",
    "            output[pv.id-1][3] = pv.l          # set tht cell parent ID\n",
    "\n",
    "    return output\n",
    "\n",
    "def write_info(vector, name):\n",
    "    '''\n",
    "    This function is to write info. of each vector.\n",
    "\n",
    "    Input: the list of vector generated by set_date() and \n",
    "           the name of output file.\n",
    "\n",
    "    '''\n",
    "    with open(name+\".txt\", \"w+\") as file:\n",
    "        for p in vector:\n",
    "            file.write(str(int(p[0]))+\" \"+\\\n",
    "                       str(int(p[1]))+\" \"+\\\n",
    "                       str(int(p[2]))+\" \"+\\\n",
    "                       str(int(p[3]))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This part is to test the matching scheme with single image\n",
    "# Input: the original image;\n",
    "#        the labeled image;\n",
    "#        the binary labeled image.\n",
    "\n",
    "vector = None\n",
    "# Feature vector construction\n",
    "global centroid\n",
    "global slope_length\n",
    "global vector\n",
    "vector = []\n",
    "max_id = 0\n",
    "for i in range(len(images)):\n",
    "    print \"  feature vector: image \", i\n",
    "    v = FEAVECTOR()\n",
    "    v.set_centroid(centroid[i])\n",
    "    v.set_spatial(slope_length[i])\n",
    "    v.set_shape(enhance_images[i], marks[i])\n",
    "    v.set_histogram()\n",
    "    v.add_label()\n",
    "    v.add_id(marks[i].max(), i)\n",
    "    v.add_efd()\n",
    "    v.add_area()\n",
    "    v.add_co_occurrence()\n",
    "    vector.append(v.generate_vector())\n",
    "    print \"num of nuclei: \", len(vector[i])\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print \"finish\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is to get the sub-image for each cell and save as file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 70\n",
    "counter = 0\n",
    "for i, vt in enumerate(vector):\n",
    "    print \"Image: \", i\n",
    "    for v in vt:\n",
    "        h, w = v.s[1].shape[:2]\n",
    "        extend_x = (image_size - w) / 2\n",
    "        extend_y = (image_size - h) / 2\n",
    "        temp = cv2.copyMakeBorder(v.s[1], \\\n",
    "                                  extend_y, (image_size-extend_y-h), \\\n",
    "                                  extend_x, (image_size-extend_x-w), \\\n",
    "                                  cv2.BORDER_CONSTANT, value=0)\n",
    "        write_mask8(temp, \"cell_image\"+str(i)+\"_\", counter)\n",
    "        counter += 1\n",
    "        clear_output(wait=True)\n",
    "print \"finish!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This part is to using ratio of the two axises of inerial as mitosis refinement to mactch cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SIMPLE_MATCH():\n",
    "    '''\n",
    "    This class is simple matching a nucleus into a nucleus in the previous frame by \n",
    "    find the nearest neighborhood. \n",
    "\n",
    "    '''\n",
    "    def __init__(self, index0, index1, images, vectors):\n",
    "        self.v0 = cp.copy(vectors[index0])\n",
    "        self.v1 = cp.copy(vectors[index1])\n",
    "        self.i0 = index0\n",
    "        self.i1 = index1\n",
    "        self.images = images\n",
    "        self.vs = cp.copy(vectors)\n",
    "\n",
    "    def distance_measure(self, pv0, pv1, alpha1=0.5, alpha2=0.25, alpha3=0.25, phase = 1):\n",
    "        '''\n",
    "        This function measures the distence of the two given feature vectors. \n",
    "\n",
    "        This distance metrics we use is:\n",
    "                        d(v(k, i), v(k+1, j)) = alpha1 * d(c(k, i), c(k+1, j)) + \n",
    "                                                alpha2 * q1 * d(s(k, i), s(k+1, j)) +\n",
    "                                                alpha3 * q2 * d(h(k, i), h(k+1, j)) +\n",
    "                                                alpha4 * d(e(k, i), e(k+1, j))\n",
    "        Input: The two given feature vectors, \n",
    "               and the set of parameters.\n",
    "\n",
    "        Output: the distance of the two given vectors. \n",
    "\n",
    "        '''\n",
    "        def centriod_distance(c0, c1, D=30.):\n",
    "            dist = np.sqrt((c0[0]-c1[0])**2 + (c0[1]-c1[1])**2)\n",
    "            return dist/D if dist < D else 1\n",
    "\n",
    "        def efd_distance(r0, r1, order=8):\n",
    "            def find_max(max_value, test):\n",
    "                if max_value < test:\n",
    "                    return test\n",
    "                return max_value\n",
    "            dis = 0\n",
    "            if type(r0) is not int and type(r1) is not int:\n",
    "                max_a, max_b, max_c, max_d = 0, 0, 0, 0\n",
    "                for o in range(order):\n",
    "                    dis += ((r0[o][0]-r1[o][0])**2+\\\n",
    "                            (r0[o][1]-r1[o][1])**2+\\\n",
    "                            (r0[o][2]-r1[o][2])**2+\\\n",
    "                            (r0[o][3]-r1[o][3])**2)\n",
    "                    max_a = find_max(max_a, (r0[o][0]-r1[o][0])**2)\n",
    "                    max_b = find_max(max_b, (r0[o][1]-r1[o][1])**2)\n",
    "                    max_c = find_max(max_c, (r0[o][2]-r1[o][2])**2)\n",
    "                    max_d = find_max(max_d, (r0[o][3]-r1[o][3])**2)\n",
    "                dis /= (order*(max_a+max_b+max_c+max_d))\n",
    "                if dis > 1.1:\n",
    "                    print dis, max_a, max_b, max_c, max_d\n",
    "                    raise\n",
    "            else:\n",
    "                dis = 1\n",
    "            return dis\n",
    "\n",
    "        def cm_distance(cm0, cm1): \n",
    "            return ((cm0[0]-cm1[0])**2+\\\n",
    "                   (cm0[1]-cm1[1])**2+\\\n",
    "                   (cm0[2]-cm1[2])**2+\\\n",
    "                   (cm0[3]-cm1[3])**2)/\\\n",
    "                   (max(cm0[0],cm1[0])**2+\\\n",
    "                    max(cm0[1],cm1[1])**2+\\\n",
    "                    max(cm0[2],cm1[2])**2+\\\n",
    "                    max(cm0[3],cm1[3])**2)\n",
    "\n",
    "        if len(pv0.s[0]) and len(pv1.s[0]):\n",
    "            dist = \talpha1 * centriod_distance(pv0.c, pv1.c)+ \\\n",
    "                    alpha2 * efd_distance(pv0.r, pv1.r, order=8) * phase + \\\n",
    "                    alpha3 * cm_distance(pv0.cm[0], pv1.cm[0]) * phase\n",
    "        else:\n",
    "            dist = Max_dis\n",
    "\n",
    "        return dist\n",
    "\n",
    "    def phase_identify(self, pv1, min_times_MA2ma = 2, RNN=False):\n",
    "        '''\n",
    "        Phase identification returns 0 when mitosis appears, vice versa.\n",
    "\n",
    "        '''\n",
    "        if not RNN:\n",
    "            _, contours, hierarchy = cv2.findContours(pv1.s[0].astype(np.uint8), 1, 2)\n",
    "            if not len(contours):\n",
    "                return 1\n",
    "            cnt = contours[0]\n",
    "            if len(cnt) >= 5:\n",
    "                (x,y),(ma,MA),angle = cv2.fitEllipse(cnt)\n",
    "                if ma and MA/ma > min_times_MA2ma:\n",
    "                    return 0\n",
    "                elif not ma and MA:\n",
    "                    return 0\n",
    "                else:\n",
    "                    return 1\n",
    "            else:\n",
    "                return 1\n",
    "\n",
    "        else:\n",
    "            try: \n",
    "                if model.predict([pv1.r.reshape(40)])[-1]:\n",
    "                    return 0\n",
    "                else: \n",
    "                    return 1\n",
    "            except AttributeError:\n",
    "                return 1\n",
    "\n",
    "    def find_match(self, max_distance=1,a_1=0.5,a_2=0.25,a_3=0.25, rnn=False):\n",
    "        '''\n",
    "        This function is to find the nearest neighborhood between two\n",
    "        successive frame.\n",
    "\n",
    "        '''\n",
    "        def centriod_distance(c0, c1, D=30.):\n",
    "            dist = np.sqrt((c0[0]-c1[0])**2 + (c0[1]-c1[1])**2)\n",
    "            return dist/D if dist < D else 1\n",
    "\n",
    "        for i, pv1 in enumerate(self.v1):\n",
    "            dist = np.ones((len(self.v0), 3), np.float32)*max_distance\n",
    "            count = 0\n",
    "            q = self.phase_identify(pv1, 3, RNN=rnn)\n",
    "            for j, pv0 in enumerate(self.v0):\n",
    "                if centriod_distance(pv0.c, pv1.c) < 1 and pv0.a:\n",
    "                    dist[count][0] = self.distance_measure(pv0, pv1, alpha1=a_1, alpha2=a_2, alpha3=a_3, phase=q)\n",
    "                    dist[count][1] = pv0.l\n",
    "                    dist[count][2] = pv0.id\n",
    "                    count += 1\n",
    "\n",
    "            sort_dist = sorted(dist, key=lambda a_entry: a_entry[0])\n",
    "            print \"dis: \", sort_dist[0][0]\n",
    "            if sort_dist[0][0] < max_distance:\n",
    "                self.v1[i].l = sort_dist[0][1]\n",
    "                self.v1[i].id = sort_dist[0][2]\n",
    "\n",
    "    def mitosis_refine(self, rnn=False):\n",
    "        '''\n",
    "        This function is to find died cell due to the by mitosis. \n",
    "\n",
    "        '''\n",
    "        def find_sibling(pv0):\n",
    "            '''\n",
    "            This function is to find sibling cells according to the centroid of\n",
    "            pv0. The criteria of sibling is:\n",
    "                    1. the jaccard cooeficient of the two cells is above 0.5\n",
    "                    2. the sum of the two areas should in the range [A, 2.5A], where\n",
    "                       A is the area of the pv0\n",
    "                    3. the position of the two cells should be not larger than 20 pixels.\n",
    "\n",
    "            Input: pv0: the parent cell that you want to find siblings;\n",
    "\n",
    "            Output: the index of the siblings.\n",
    "\n",
    "            '''\n",
    "            def maxsize_image(image1, image2):\n",
    "                y1, x1 = np.where(image1)\n",
    "                y2, x2 = np.where(image2)\n",
    "                return min(min(x1), min(x2)), min(min(y1), min(y2)), \\\n",
    "                       max(max(x1), max(x2)), max(max(y1), max(y2)),\n",
    "\n",
    "            def symmetry(image, shape):\n",
    "                h, w = image.shape[:2] \n",
    "                newimg = np.zeros(shape)\n",
    "                newimg[:h, :w] = image\n",
    "                v = float(shape[0] - h)/2.\n",
    "                u = float(shape[1] - w)/2.\n",
    "                M = np.float32([[1,0,u],[0,1,v]])\n",
    "                return cv2.warpAffine(newimg,M,(shape[1],shape[0]))\n",
    "\n",
    "            def jaccard(s0, s1):\n",
    "                minx, miny, maxx, maxy = maxsize_image(s0, s1)\n",
    "                height = maxy - miny + 1\n",
    "                width = maxx - minx + 1\n",
    "\n",
    "                img0 = symmetry(s0, (height, width))\n",
    "                img1 = symmetry(s1, (height, width))\n",
    "\n",
    "                num = 0.\n",
    "                deno = 0.\n",
    "                for y in range(height):\n",
    "                    for x in range(width):\n",
    "                        if img0[y, x] and img1[y, x]:\n",
    "                            num += 1\n",
    "                        if img0[y, x] or img1[y, x]:\n",
    "                            deno += 1\n",
    "\n",
    "                return num/deno\n",
    "\n",
    "            sibling_cand = []\n",
    "            for i, pv1 in enumerate(self.v1): \n",
    "                if np.linalg.norm(pv1.c-pv0.c) < 50:\n",
    "                    sibling_cand.append([pv1, i])\n",
    "\n",
    "            sibling_pair = []\n",
    "            area = pv0.s[0].sum()\n",
    "            jaccard_value = []\n",
    "            for sibling0 in sibling_cand:\n",
    "                for sibling1 in sibling_cand:\n",
    "                    if (sibling1[0].c != sibling0[0].c).all():\n",
    "                        sum_area = sibling1[0].s[0].sum()+sibling0[0].s[0].sum()\n",
    "                        similarity = jaccard(sibling0[0].s[0], sibling1[0].s[0])\n",
    "                        if similarity > 0.4 and (sum_area > 2*area):\n",
    "                            sibling_pair.append([sibling0, sibling1])\n",
    "                            jaccard_value.append(similarity)\n",
    "            if len(jaccard_value):\n",
    "                return sibling_pair[np.argmax(jaccard_value)]\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        v1_ids = []\n",
    "        for pv1 in self.v1:\n",
    "            v1_ids.append(pv1.id)\n",
    "\n",
    "        for i, pv0 in enumerate(self.v0):\n",
    "            if pv0.id not in v1_ids and len(pv0.s[0]) and self.phase_identify(pv0, 3, RNN=rnn):\n",
    "                sibling = find_sibling(pv0)\n",
    "                if sibling:\n",
    "                    [s0, s1] = sibling\n",
    "                    if s0[0].l==0 and s1[0].l==0 and \\\n",
    "                       s0[0].id==-1 and s1[0].id==-1:\n",
    "                        self.v1[s0[1]].l = pv0.id\n",
    "                        self.v1[s1[1]].l = pv0.id\n",
    "\n",
    "        return self.v1\n",
    "\n",
    "    def match_missing(self, mask, max_frame = 1, max_distance = 10, min_shape_similarity = 0.6):\n",
    "        '''\n",
    "        This function is to match the cells that didn't show in the last frame caused by \n",
    "        program fault. In order to match them, we need to seach the cell in the previous \n",
    "        frame with in the certain range and with similar shape.  \n",
    "\n",
    "        '''\n",
    "        def centriod_distance(c0, c1):\n",
    "            dist = np.sqrt((c0[0]-c1[0])**2 + (c0[1]-c1[1])**2)\n",
    "            return dist\n",
    "\n",
    "        def maxsize_image(image1, image2):\n",
    "            y1, x1 = np.where(image1)\n",
    "            y2, x2 = np.where(image2)\n",
    "            return min(min(x1), min(x2)), min(min(y1), min(y2)), \\\n",
    "                   max(max(x1), max(x2)), max(max(y1), max(y2)),\n",
    "\n",
    "        def symmetry(image, shape):\n",
    "            h, w = image.shape[:2] \n",
    "            newimg = np.zeros(shape)\n",
    "            newimg[:h, :w] = image\n",
    "            v = float(shape[0] - h)/2.\n",
    "            u = float(shape[1] - w)/2.\n",
    "            M = np.float32([[1,0,u],[0,1,v]])\n",
    "            return cv2.warpAffine(newimg,M,(shape[1],shape[0]))\n",
    "\n",
    "        def shape_similarity(s0, s1):\n",
    "            if len(s0) and len(s1):\n",
    "                minx, miny, maxx, maxy = maxsize_image(s0, s1)\n",
    "                height = maxy - miny + 1\n",
    "                width = maxx - minx + 1\n",
    "\n",
    "                img0 = symmetry(s0, (height, width))\n",
    "                img1 = symmetry(s1, (height, width))\n",
    "\n",
    "                num = 0.\n",
    "                deno = 0.\n",
    "                for y in range(height):\n",
    "                    for x in range(width):\n",
    "                        if img0[y, x] and img1[y, x]:\n",
    "                            num += 1\n",
    "                        if img0[y, x] or img1[y, x]:\n",
    "                            deno += 1\n",
    "                return num/deno\n",
    "\n",
    "            else:\n",
    "                return 0.\n",
    "\n",
    "        def add_marker(index_find, index_new, pv0_id):\n",
    "            temp = mask[index_new]\n",
    "            find = mask[index_find]\n",
    "            temp[find==pv0_id] = pv0_id\n",
    "            return temp\n",
    "\n",
    "        for i, pv1 in enumerate(self.v1):\n",
    "            if pv1.id == -1:\n",
    "                for index in range(1, max_frame+1):\n",
    "                    if self.i0-index >= 0:\n",
    "                        vt = self.vs[self.i0-index]\n",
    "                        for pv0 in vt:\n",
    "                            if centriod_distance(pv0.c, pv1.c) < max_distance and \\\n",
    "                                shape_similarity(pv0.s[0], pv1.s[0]) > min_shape_similarity:\n",
    "                                self.v1[i].id = pv0.id\n",
    "                                self.v1[i].l = pv0.l\n",
    "                                print \"missing in frame: \", self.i1, \"find in frame: \", \\\n",
    "                                       self.i0-index, \"ID: \", pv0.id, \" at: \", pv0.c\n",
    "                                for i in range(self.i0-index+1, self.i1):\n",
    "                                    mask[i] = add_marker(self.i0-index, i, pv0.id)\n",
    "        return mask\n",
    "\n",
    "    def new_id(self, vectors):\n",
    "        '''\n",
    "        This function is to add new labels for the necles that are marked as -1.\n",
    "\n",
    "\n",
    "        '''\n",
    "        def find_max_id(vectors):\n",
    "            max_id = 0\n",
    "            for vt in vectors:\n",
    "                for pt in vt:\n",
    "                    if pt.id > max_id:\n",
    "                        max_id = pt.id \n",
    "            return max_id\n",
    "        max_id = find_max_id(self.vs)\n",
    "        max_id += 1\n",
    "        for i, pv1 in enumerate(self.v1):\n",
    "            if pv1.id == -1:\n",
    "                self.v1[i].id = max_id\n",
    "                max_id += 1\n",
    "\n",
    "    def generate_mask(self, marker, index, isfinal=False):\n",
    "        '''\n",
    "        This function is to generate a 16-bit image as mask image. \n",
    "\n",
    "        '''\n",
    "        h, w = marker.shape[:2]\n",
    "        mask = np.zeros((h, w), np.uint16)\n",
    "        pts = list(set(marker[marker>0]))\n",
    "        if not isfinal:\n",
    "            assert len(pts)==len(self.v0), 'len(pts): %s != len(self.v0): %s' % (len(pts), len(self.v0))\n",
    "            for pt, pv in zip(pts, self.v0):\n",
    "                mask[marker==pt] = pv.id\n",
    "\n",
    "        else:\n",
    "            assert len(pts)==len(self.v1), 'len(pts): %s != len(self.v0): %s' % (len(pts), len(self.v1))\n",
    "            for pt, pv in zip(pts, self.v1):\n",
    "                mask[marker==pt] = pv.id\n",
    "\n",
    "        os.chdir(\".\")\n",
    "        write_mask16(mask, \"mask\", index)\n",
    "        os.chdir(os.pardir)\n",
    "        return mask\t\n",
    "\n",
    "    def return_vectors(self):\n",
    "        '''\n",
    "        This function is to return the vectors that we have already \n",
    "        changed.\n",
    "\n",
    "        Output: the vectors from the k+1 frame.\n",
    "\n",
    "        '''\t\n",
    "        return self.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy as cp\n",
    "\n",
    "mask = []\n",
    "temp_vector = cp.deepcopy(vector)\n",
    "\n",
    "# Feature matching\n",
    "for i in range(len(images)-1):\n",
    "    print \"  Feature matching: image \", i\n",
    "    m = SIMPLE_MATCH(i,i+1,[images[i], images[i+1]], temp_vector)\n",
    "    mask.append(m.generate_mask(marks[i], i))\n",
    "    m.find_match(0.7,0.7,0.15,0.15)\n",
    "    temp_vector[i+1] = m.mitosis_refine()\n",
    "    m.new_id(temp_vector)\n",
    "    temp_vector[i+1] = m.return_vectors()\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print \"  Feature matching: image \", i+1\n",
    "mask.append(m.generate_mask(marks[i+1], i+1, True))\n",
    "os.chdir(\".\")\n",
    "cells = set_date(temp_vector)\n",
    "write_info(cells, \"res_track\")\n",
    "print \"finish!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part generates the final marked result in \"gif\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write gif image showing the final result\n",
    "def find_max_id(temp_vector):\n",
    "    max_id = 0\n",
    "    for pv in temp_vector:\n",
    "        for p in pv:\n",
    "            if p.id > max_id:\n",
    "                max_id = p.id\n",
    "    return max_id\n",
    "\n",
    "# This part is to mark the result in the normolized image and \n",
    "# write the gif image.\n",
    "max_id = find_max_id(temp_vector)\n",
    "colors = [np.random.randint(0, 255, size=max_id),\\\n",
    "          np.random.randint(0, 255, size=max_id),\\\n",
    "          np.random.randint(0, 255, size=max_id)]\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "selecy_id = 9\n",
    "enhance_imgs = []\n",
    "for i, m in enumerate(mask):\n",
    "    print \"  write the gif image: image \", i\n",
    "    enhance_imgs.append(cv2.cvtColor(enhance_images[i],cv2.COLOR_GRAY2RGB))\n",
    "    for pv in temp_vector[i]:\n",
    "        center = pv.c\n",
    "        if not pv.l:\n",
    "            color = (colors[0][int(pv.id)-1],\\\n",
    "                     colors[1][int(pv.id)-1],\\\n",
    "                     colors[2][int(pv.id)-1],)\n",
    "        else:\n",
    "            color = (colors[0][int(pv.l)-1],\\\n",
    "                     colors[1][int(pv.l)-1],\\\n",
    "                     colors[2][int(pv.l)-1],)\n",
    "\n",
    "        if m[center[0], center[1]]:\n",
    "            enhance_imgs[i][m==pv.id] = color\n",
    "            cv2.putText(enhance_imgs[i],\\\n",
    "                        str(int(pv.id)),(int(pv.c[1]), \\\n",
    "                        int(pv.c[0])), \n",
    "                        font, 0.5,\\\n",
    "                        (255,255,255),1)\n",
    "    clear_output(wait=True)\n",
    "os.chdir(\"PATH_TO_RESULT\")\n",
    "imageio.mimsave('mitosis_final.gif', enhance_imgs, duration=0.6)\n",
    "print \"finish!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
